---
tags:
  - formation
  - cloud
  - architecture
  - haute-disponibilite
  - disaster-recovery
  - scalabilite
---

# Module 5 : Architecture Cloud (HA, DR, Scalabilit√©)

## Objectifs du Module

√Ä la fin de ce module, vous serez capable de :

- :fontawesome-solid-heart-pulse: Concevoir une architecture haute disponibilit√©
- :fontawesome-solid-rotate: Planifier une strat√©gie de Disaster Recovery
- :fontawesome-solid-arrows-up-down: Comprendre les types de scalabilit√©
- :fontawesome-solid-diagram-project: Reconna√Ætre les patterns d'architecture cloud
- :fontawesome-solid-calculator: Calculer et interpr√©ter les SLA

---

## 1. Haute Disponibilit√© (HA)

### 1.1 Qu'est-ce que la Haute Disponibilit√© ?

!!! info "D√©finition"
    La **haute disponibilit√©** est la capacit√© d'un syst√®me √† rester op√©rationnel malgr√© la d√©faillance de certains composants.

```mermaid
graph TB
    subgraph "‚ùå Sans HA"
        SINGLE["üíª Serveur unique"]
        SINGLE --> FAIL["üí• Panne = Service DOWN"]
    end

    subgraph "‚úÖ Avec HA"
        LB["‚öñÔ∏è Load Balancer"]
        S1["üíª Serveur 1"]
        S2["üíª Serveur 2"]
        S3["üíª Serveur 3"]
        LB --> S1
        LB --> S2
        LB --> S3
        S1 --> OK["Panne S1 = Service OK"]
    end

    style FAIL fill:#f44336,color:#fff
    style OK fill:#4caf50,color:#fff
```

### 1.2 Les Niveaux de Disponibilit√© (SLA)

| Disponibilit√© | Downtime/an | Downtime/mois | Cat√©gorie |
|---------------|-------------|---------------|-----------|
| **99%** | 3.65 jours | 7.3 heures | Standard |
| **99.9%** | 8.76 heures | 43.8 minutes | √âlev√© |
| **99.95%** | 4.38 heures | 21.9 minutes | Tr√®s √©lev√© |
| **99.99%** | 52.6 minutes | 4.38 minutes | Critique |
| **99.999%** | 5.26 minutes | 26.3 secondes | Mission critique |

!!! example "SLA Cloud Providers"
    | Service | AWS | Azure | GCP |
    |---------|-----|-------|-----|
    | **VM unique** | 99.5% | 99.9% | 99.5% |
    | **VM multi-AZ** | 99.99% | 99.99% | 99.99% |
    | **Object Storage** | 99.99% | 99.99% | 99.99% |
    | **Managed DB multi-AZ** | 99.95% | 99.99% | 99.95% |

### 1.3 Calcul du SLA Composite

```mermaid
graph LR
    LB["Load Balancer<br/>99.99%"] --> APP["App (2 VMs)<br/>99.99%"]
    APP --> DB["Database<br/>99.95%"]

    TOTAL["SLA Total = ?"]

    style TOTAL fill:#ff9800,color:#fff
```

**Formule** : SLA composite = SLA1 √ó SLA2 √ó SLA3

```
SLA = 99.99% √ó 99.99% √ó 99.95% = 99.93%
```

!!! warning "Attention"
    Chaque composant **diminue** la disponibilit√© globale. Plus vous avez de composants, plus le SLA baisse.

### 1.4 Patterns de Haute Disponibilit√©

#### Active-Active

```mermaid
graph TB
    LB["‚öñÔ∏è Load Balancer"]
    subgraph "Zone A"
        A1["üíª Server A1<br/>ACTIVE"]
    end
    subgraph "Zone B"
        A2["üíª Server A2<br/>ACTIVE"]
    end

    LB --> A1
    LB --> A2

    style A1 fill:#4caf50,color:#fff
    style A2 fill:#4caf50,color:#fff
```

- Les deux serveurs traitent le trafic
- Capacit√© = Server1 + Server2
- Si un tombe, l'autre absorbe la charge

#### Active-Passive (Standby)

```mermaid
graph TB
    LB["‚öñÔ∏è Load Balancer"]
    subgraph "Zone A"
        A1["üíª Server A1<br/>ACTIVE"]
    end
    subgraph "Zone B"
        A2["üíª Server A2<br/>STANDBY"]
    end

    LB --> A1
    A1 -.->|"Failover"| A2

    style A1 fill:#4caf50,color:#fff
    style A2 fill:#ff9800,color:#fff
```

- Un seul serveur traite le trafic
- Le second attend en standby
- Bascule automatique en cas de panne

---

## 2. Disaster Recovery (DR)

### 2.1 RPO et RTO

```mermaid
graph LR
    subgraph "Timeline d'un Incident"
        BACKUP["üì∏ Dernier Backup"]
        DISASTER["üí• Incident"]
        RECOVERY["‚úÖ Reprise"]
    end

    BACKUP -->|"RPO<br/>(donn√©es perdues)"| DISASTER
    DISASTER -->|"RTO<br/>(temps d'arr√™t)"| RECOVERY

    style DISASTER fill:#f44336,color:#fff
    style RECOVERY fill:#4caf50,color:#fff
```

| M√©trique | D√©finition | Question |
|----------|------------|----------|
| **RPO** (Recovery Point Objective) | Quantit√© de donn√©es qu'on accepte de perdre | "Combien de temps de donn√©es perdues est acceptable ?" |
| **RTO** (Recovery Time Objective) | Temps pour r√©tablir le service | "En combien de temps doit-on √™tre de nouveau op√©rationnel ?" |

### 2.2 Strat√©gies de DR

```mermaid
graph TB
    subgraph "Strat√©gies DR (co√ªt croissant)"
        BACKUP["üíæ Backup/Restore<br/>RTO: heures/jours<br/>Co√ªt: $"]
        PILOT["üî• Pilot Light<br/>RTO: dizaines de minutes<br/>Co√ªt: $$"]
        WARM["‚ô®Ô∏è Warm Standby<br/>RTO: minutes<br/>Co√ªt: $$$"]
        HOT["üî• Hot Standby<br/>RTO: secondes<br/>Co√ªt: $$$$"]
    end

    BACKUP --> PILOT --> WARM --> HOT

    style BACKUP fill:#4caf50,color:#fff
    style PILOT fill:#8bc34a,color:#fff
    style WARM fill:#ff9800,color:#fff
    style HOT fill:#f44336,color:#fff
```

| Strat√©gie | Description | RTO | RPO | Co√ªt |
|-----------|-------------|-----|-----|------|
| **Backup/Restore** | Donn√©es sauvegard√©es, infra recr√©√©e | Heures/Jours | Heures | $ |
| **Pilot Light** | Core infra tourne, reste √† d√©marrer | 10-30 min | Minutes | $$ |
| **Warm Standby** | Infra compl√®te tourne √† √©chelle r√©duite | Minutes | Minutes | $$$ |
| **Hot Standby** | Infra identique en active-active | Secondes | Temps r√©el | $$$$ |

### 2.3 Architecture Multi-R√©gion

```mermaid
graph TB
    subgraph "Region: Europe (Primary)"
        LB1["‚öñÔ∏è LB"]
        APP1["üíª App"]
        DB1["üóÑÔ∏è DB Primary"]
    end

    subgraph "Region: US (DR)"
        LB2["‚öñÔ∏è LB"]
        APP2["üíª App (scaled down)"]
        DB2["üóÑÔ∏è DB Replica"]
    end

    DNS["üåê DNS (Route 53, Traffic Manager)"]

    USER["üë• Users"] --> DNS
    DNS -->|"Normal"| LB1
    DNS -.->|"Failover"| LB2
    DB1 -->|"Replication"| DB2

    style DB1 fill:#4caf50,color:#fff
    style DB2 fill:#ff9800,color:#fff
```

---

## 3. Scalabilit√©

### 3.1 Scaling Vertical vs Horizontal

```mermaid
graph TB
    subgraph "‚¨ÜÔ∏è Scaling Vertical (Scale Up)"
        V1["üíª Small<br/>2 CPU, 4GB"]
        V2["üíª Medium<br/>4 CPU, 8GB"]
        V3["üíª Large<br/>8 CPU, 16GB"]
        V1 --> V2 --> V3
    end

    subgraph "‚û°Ô∏è Scaling Horizontal (Scale Out)"
        H1["üíª Server 1"]
        H2["üíª Server 2"]
        H3["üíª Server 3"]
        H4["üíª Server 4"]
    end

    style V3 fill:#4caf50,color:#fff
    style H4 fill:#2196f3,color:#fff
```

| Type | Description | Avantages | Inconv√©nients |
|------|-------------|-----------|---------------|
| **Vertical** | Augmenter la taille d'une machine | Simple, pas de changement d'archi | Limite physique, downtime |
| **Horizontal** | Ajouter plus de machines | Pas de limite, HA naturelle | Complexit√© (stateless, LB) |

### 3.2 Auto Scaling

```mermaid
graph LR
    subgraph "Auto Scaling"
        METRIC["üìä M√©triques<br/>(CPU, RAM, Requests)"]
        POLICY["üìú Politique<br/>Si CPU > 70%"]
        ACTION["‚ö° Action<br/>Ajouter 2 instances"]
    end

    METRIC --> POLICY --> ACTION

    style POLICY fill:#ff9800,color:#fff
```

**M√©triques courantes pour le scaling :**

| M√©trique | Description | Exemple de seuil |
|----------|-------------|------------------|
| **CPU** | Utilisation processeur | > 70% ‚Üí scale up |
| **Memory** | Utilisation m√©moire | > 80% ‚Üí scale up |
| **Requests/sec** | Nombre de requ√™tes | > 1000 req/s ‚Üí scale up |
| **Queue depth** | Messages en attente | > 100 messages ‚Üí scale up |
| **Custom** | M√©trique business | > X transactions/min |

### 3.3 Stateless vs Stateful

!!! warning "Cl√© du Scaling Horizontal"
    Pour scaler horizontalement, votre application doit √™tre **stateless** (sans √©tat local).

```mermaid
graph TB
    subgraph "‚ùå Stateful (Non scalable)"
        S1["üíª Server<br/>Session en m√©moire"]
        USER1["üë§ User A<br/>Session sur Server 1"]
    end

    subgraph "‚úÖ Stateless (Scalable)"
        LB["‚öñÔ∏è Load Balancer"]
        SS1["üíª Server 1"]
        SS2["üíª Server 2"]
        SS3["üíª Server 3"]
        CACHE["‚ö° Redis<br/>(Sessions)"]

        LB --> SS1
        LB --> SS2
        LB --> SS3
        SS1 --> CACHE
        SS2 --> CACHE
        SS3 --> CACHE
    end

    style S1 fill:#f44336,color:#fff
    style CACHE fill:#4caf50,color:#fff
```

**Comment rendre une app stateless :**

- Sessions ‚Üí Store externe (Redis, DynamoDB)
- Fichiers upload√©s ‚Üí Object Storage (S3)
- Cache ‚Üí Cache distribu√© (ElastiCache)
- Base de donn√©es ‚Üí Service manag√© (RDS)

---

## 4. Patterns d'Architecture Cloud

### 4.1 Architecture N-Tier

```mermaid
graph TB
    subgraph "Presentation Tier"
        WEB["üåê Web Servers<br/>(Frontend)"]
    end

    subgraph "Application Tier"
        APP["‚öôÔ∏è App Servers<br/>(Backend API)"]
    end

    subgraph "Data Tier"
        DB["üóÑÔ∏è Database"]
        CACHE["‚ö° Cache"]
    end

    WEB --> APP
    APP --> DB
    APP --> CACHE

    style WEB fill:#2196f3,color:#fff
    style APP fill:#4caf50,color:#fff
    style DB fill:#ff9800,color:#fff
```

### 4.2 Microservices

```mermaid
graph TB
    subgraph "Microservices Architecture"
        GW["üö™ API Gateway"]

        subgraph "Services"
            SVC1["üë§ User Service"]
            SVC2["üí≥ Payment Service"]
            SVC3["üì¶ Order Service"]
            SVC4["üìß Notification Service"]
        end

        subgraph "Data"
            DB1["üóÑÔ∏è User DB"]
            DB2["üóÑÔ∏è Payment DB"]
            DB3["üóÑÔ∏è Order DB"]
        end

        QUEUE["üì¨ Message Queue"]
    end

    GW --> SVC1
    GW --> SVC2
    GW --> SVC3
    SVC1 --> DB1
    SVC2 --> DB2
    SVC3 --> DB3
    SVC3 --> QUEUE
    QUEUE --> SVC4

    style GW fill:#9c27b0,color:#fff
```

**Avantages :**
- Scaling ind√©pendant par service
- D√©ploiement ind√©pendant
- Technologie adapt√©e par service
- √âquipes autonomes

### 4.3 Event-Driven Architecture

```mermaid
graph LR
    subgraph "Producers"
        P1["üì± Mobile App"]
        P2["üåê Web App"]
        P3["‚öôÔ∏è Backend"]
    end

    BROKER["üì¨ Event Broker<br/>(Kafka, EventBridge)"]

    subgraph "Consumers"
        C1["üìä Analytics"]
        C2["üìß Notifications"]
        C3["üóÑÔ∏è Data Lake"]
    end

    P1 --> BROKER
    P2 --> BROKER
    P3 --> BROKER
    BROKER --> C1
    BROKER --> C2
    BROKER --> C3

    style BROKER fill:#ff9800,color:#fff
```

---

## 5. Well-Architected Framework

### 5.1 Les 6 Piliers

```mermaid
mindmap
  root((Well-Architected))
    Operational Excellence
      Automatisation
      Observabilit√©
      Am√©lioration continue
    Security
      IAM
      D√©tection
      Protection donn√©es
    Reliability
      HA
      DR
      Gestion pannes
    Performance Efficiency
      S√©lection ressources
      Monitoring
      Optimisation
    Cost Optimization
      FinOps
      Right-sizing
      Reserved capacity
    Sustainability
      Efficacit√© √©nerg√©tique
      Impact environnemental
```

### 5.2 Questions Cl√©s par Pilier

| Pilier | Questions √† se poser |
|--------|----------------------|
| **Operational Excellence** | Comment d√©ployez-vous ? Comment d√©tectez-vous les probl√®mes ? |
| **Security** | Qui a acc√®s ? Comment prot√©gez-vous les donn√©es ? |
| **Reliability** | Que se passe-t-il si X tombe ? Quel est votre RTO/RPO ? |
| **Performance** | Comment g√©rez-vous les pics ? Avez-vous des goulots ? |
| **Cost Optimization** | Payez-vous pour des ressources inutilis√©es ? |
| **Sustainability** | Quel est l'impact carbone ? Pouvez-vous optimiser ? |

---

## 6. Quiz de Validation

!!! question "Question 1"
    Quelle est la diff√©rence entre RPO et RTO ?

    ??? success "R√©ponse"
        - **RPO** (Recovery Point Objective) : Quantit√© de donn√©es acceptable √† perdre (temps depuis le dernier backup)
        - **RTO** (Recovery Time Objective) : Temps acceptable pour restaurer le service

        Exemple : RPO de 1h signifie qu'on accepte de perdre 1h de donn√©es. RTO de 30min signifie qu'on doit √™tre op√©rationnel en 30 minutes.

!!! question "Question 2"
    Si vous avez 3 composants avec des SLA de 99.9%, 99.95% et 99.9%, quel est le SLA composite ?

    ??? success "R√©ponse"
        SLA = 99.9% √ó 99.95% √ó 99.9% = **99.75%**

        Le SLA composite est toujours inf√©rieur au SLA le plus faible.

!!! question "Question 3"
    Quelle strat√©gie DR a le RTO le plus court ?

    ??? success "R√©ponse"
        **Hot Standby** (Active-Active)

        L'infrastructure de DR est identique et tourne en permanence. Le failover est quasi-instantan√© (secondes).

!!! question "Question 4"
    Pourquoi une application doit-elle √™tre stateless pour scaler horizontalement ?

    ??? success "R√©ponse"
        Si l'√©tat (session, fichiers) est stock√© localement sur un serveur, les requ√™tes suivantes doivent aller sur le m√™me serveur. Impossible de distribuer la charge.

        Avec une app stateless, n'importe quel serveur peut traiter n'importe quelle requ√™te.

---

## 7. R√©sum√©

| Concept | Description | M√©trique cl√© |
|---------|-------------|--------------|
| **Haute Disponibilit√©** | Service reste up malgr√© pannes | SLA (99.9%, 99.99%...) |
| **Disaster Recovery** | Reprise apr√®s sinistre majeur | RTO, RPO |
| **Scalabilit√© Verticale** | Augmenter la taille | Limite physique |
| **Scalabilit√© Horizontale** | Ajouter des instances | Stateless requis |
| **Auto Scaling** | Scaling automatique | M√©triques, seuils |

---

## Navigation

| Pr√©c√©dent | Suivant |
|-----------|---------|
| [‚Üê Module 4 : S√©curit√© & Conformit√©](04-module.md) | [Module 6 : FinOps & Co√ªts ‚Üí](06-module.md) |
