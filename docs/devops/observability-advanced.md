# Advanced Observability: Alerting & ELK

`#alertmanager` `#blackbox` `#elk` `#sre` `#monitoring`

Passer de la visualisation passive Ã  l'action proactive. Gestion des astreintes et logs Ã  grande Ã©chelle.

---

## AlertManager : Le Cerveau des Alertes

### Pourquoi Prometheus ne Suffit Pas ?

**Prometheus = Collecte + Ã‰valuation des alertes**
**AlertManager = DÃ©duplication + Groupement + Routage + Silence**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SANS ALERTMANAGER (Chaos)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Datacenter down â†’ 50 serveurs down                         â”‚
â”‚                                                              â”‚
â”‚  Prometheus envoie :                                        â”‚
â”‚  â”œâ”€â”€ 50 emails "Server down"                                â”‚
â”‚  â”œâ”€â”€ 50 SMS                                                 â”‚
â”‚  â””â”€â”€ 50 appels PagerDuty                                    â”‚
â”‚                                                              â”‚
â”‚  SRE on-call :                                              â”‚
â”‚  â””â”€â”€ ğŸ“±ğŸ’¥ğŸ’¥ğŸ’¥ (150 notifications en 1 minute)               â”‚
â”‚                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              AVEC ALERTMANAGER (Intelligence)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Datacenter down â†’ 50 serveurs down                         â”‚
â”‚                                                              â”‚
â”‚  AlertManager :                                             â”‚
â”‚  â”œâ”€â”€ Groupe les 50 alertes similaires                       â”‚
â”‚  â”œâ”€â”€ Applique inhibition (datacenter down > serveurs)       â”‚
â”‚  â””â”€â”€ Envoie 1 seule notification :                          â”‚
â”‚      "Datacenter Paris DOWN - 50 serveurs affectÃ©s"         â”‚
â”‚                                                              â”‚
â”‚  SRE on-call :                                              â”‚
â”‚  â””â”€â”€ ğŸ“± (1 notification claire et actionnable)              â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**FonctionnalitÃ©s clÃ©s d'AlertManager :**

| FonctionnalitÃ© | Description | Valeur |
|----------------|-------------|--------|
| **DÃ©duplication** | Fusionne les alertes identiques | Ã‰vite les doublons |
| **Groupement** | Groupe les alertes similaires | 1 notification pour N alertes |
| **Routage** | Envoie Ã  la bonne Ã©quipe/canal | Critical â†’ PagerDuty, Warning â†’ Slack |
| **Inhibition** | Supprime les alertes dÃ©rivÃ©es | Datacenter down > Serveurs down |
| **Silences** | Mute temporairement | Maintenance planifiÃ©e |
| **Repeat Interval** | Re-notifie si non rÃ©solu | Ã‰vite l'oubli |

---

### Architecture AlertManager

```mermaid
flowchart LR
    A[Prometheus] -->|Firing alerts| B[AlertManager]

    B -->|Route: Critical| C[PagerDuty]
    B -->|Route: Warning| D[Slack]
    B -->|Route: Info| E[Email]

    B -->|Grouping| F[Group by: cluster, alertname]
    B -->|Inhibition| G[Suppress child alerts]
    B -->|Silences| H[Mute during maintenance]

    C -->|ğŸ“± Phone call| I[SRE On-call]
    D -->|ğŸ’¬ Message| J[Dev Team Channel]
    E -->|ğŸ“§ Email| K[Ops Team]
```

---

### Configuration AlertManager

**Structure du fichier `alertmanager.yml` :**

```yaml
# ============================================================
# CONFIGURATION ALERTMANAGER
# ============================================================

global:
  # RÃ©solution par dÃ©faut
  resolve_timeout: 5m

  # Config Slack globale
  slack_api_url: 'https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXX'

# ============================================================
# TEMPLATES (Personnalisation des messages)
# ============================================================

templates:
  - '/etc/alertmanager/templates/*.tmpl'

# ============================================================
# ROUTE TREE (L'Arbre de DÃ©cision)
# ============================================================

route:
  # Route racine (catch-all)
  receiver: 'default-receiver'

  # Groupement des alertes
  group_by: ['cluster', 'alertname']

  # Attendre 30s avant d'envoyer (pour grouper)
  group_wait: 30s

  # Attendre 5min avant de grouper Ã  nouveau
  group_interval: 5m

  # Re-notifier toutes les 4h si non rÃ©solu
  repeat_interval: 4h

  # Routes enfants (matching spÃ©cifique)
  routes:
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ROUTE 1 : Alertes CRITICAL â†’ PagerDuty
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - match:
        severity: critical
      receiver: 'pagerduty-critical'
      group_wait: 10s          # Envoyer rapidement (10s)
      repeat_interval: 1h      # Re-notifier toutes les heures

      routes:
        # Sous-route : Database critical â†’ Ã‰quipe DB
        - match:
            team: database
          receiver: 'pagerduty-db-team'

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ROUTE 2 : Alertes WARNING â†’ Slack
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - match:
        severity: warning
      receiver: 'slack-warnings'
      group_wait: 1m
      repeat_interval: 12h

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ROUTE 3 : Alertes INFO â†’ Email (low priority)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - match:
        severity: info
      receiver: 'email-ops'
      group_wait: 5m
      repeat_interval: 24h

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ROUTE 4 : Environnement DEV â†’ Discord (pas de pagerduty)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - match:
        environment: dev
      receiver: 'discord-dev'

# ============================================================
# RECEIVERS (Canaux de Notification)
# ============================================================

receivers:
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # DEFAULT : Slack gÃ©nÃ©ral
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - name: 'default-receiver'
    slack_configs:
      - channel: '#alerts'
        title: 'ğŸš¨ Alert: {{ .GroupLabels.alertname }}'
        text: |
          *Summary:* {{ .CommonAnnotations.summary }}
          *Description:* {{ .CommonAnnotations.description }}
          *Severity:* {{ .CommonLabels.severity }}
          *Cluster:* {{ .CommonLabels.cluster }}

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # PAGERDUTY : Alertes critiques
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - name: 'pagerduty-critical'
    pagerduty_configs:
      - service_key: '<PAGERDUTY_SERVICE_KEY>'
        description: '{{ .CommonAnnotations.summary }}'
        severity: '{{ .CommonLabels.severity }}'

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # PAGERDUTY : Ã‰quipe Database
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - name: 'pagerduty-db-team'
    pagerduty_configs:
      - service_key: '<PAGERDUTY_DB_TEAM_KEY>'
        description: '[DB] {{ .CommonAnnotations.summary }}'

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # SLACK : Warnings
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - name: 'slack-warnings'
    slack_configs:
      - channel: '#alerts-warnings'
        icon_emoji: ':warning:'
        title: 'âš ï¸ Warning: {{ .GroupLabels.alertname }}'
        text: |
          *Summary:* {{ .CommonAnnotations.summary }}
          *Cluster:* {{ .CommonLabels.cluster }}
          *Instances:* {{ .Alerts | len }} affected

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # DISCORD : Environnement Dev
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - name: 'discord-dev'
    webhook_configs:
      - url: 'https://discord.com/api/webhooks/XXXXXXXXXX/YYYYYYYYYYYYYYYYYY'
        send_resolved: true

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # EMAIL : Ops Team
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - name: 'email-ops'
    email_configs:
      - to: 'ops-team@company.com'
        from: 'alertmanager@company.com'
        smarthost: 'smtp.company.com:587'
        auth_username: 'alertmanager@company.com'
        auth_password: '<SMTP_PASSWORD>'
        headers:
          Subject: '[AlertManager] {{ .GroupLabels.alertname }}'

# ============================================================
# INHIBITION RULES (Suppression d'Alertes DÃ©rivÃ©es)
# ============================================================

inhibit_rules:
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # RÃˆGLE 1 : Datacenter down > Serveurs down
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - source_match:
      alertname: 'DatacenterDown'
      severity: 'critical'
    target_match:
      alertname: 'ServerDown'
    equal: ['datacenter']  # MÃªme datacenter

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # RÃˆGLE 2 : Node down > Services down
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - source_match:
      alertname: 'NodeDown'
    target_match_re:
      alertname: '(ServiceDown|HighMemory|HighCPU)'
    equal: ['instance']

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # RÃˆGLE 3 : Critical supprime Warning sur mÃªme instance
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['instance', 'alertname']
```

---

### Exemples de Receivers

**Slack (le plus utilisÃ©) :**

```yaml
- name: 'slack-production'
  slack_configs:
    - api_url: 'https://hooks.slack.com/services/T00000000/B00000000/XXXX'
      channel: '#alerts-prod'
      username: 'AlertManager'
      icon_emoji: ':fire:'

      title: |-
        [{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .GroupLabels.alertname }}

      text: |-
        {{ range .Alerts }}
        *Alert:* {{ .Annotations.summary }}
        *Description:* {{ .Annotations.description }}
        *Severity:* `{{ .Labels.severity }}`
        *Instance:* `{{ .Labels.instance }}`
        {{ end }}

      send_resolved: true
```

**Discord :**

```yaml
- name: 'discord-dev'
  webhook_configs:
    - url: 'https://discord.com/api/webhooks/123456789/ABCDEFGHIJKLMNOPQRSTUVWXYZ'
      send_resolved: true
      http_config:
        follow_redirects: true
```

**Microsoft Teams :**

```yaml
- name: 'teams-ops'
  webhook_configs:
    - url: 'https://outlook.office.com/webhook/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx@xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/IncomingWebhook/yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy/zzzzzzzz-zzzz-zzzz-zzzz-zzzzzzzzzzzz'
      send_resolved: true
```

---

### Tester AlertManager

```bash
# CrÃ©er une alerte de test
curl -X POST http://localhost:9093/api/v1/alerts -d '[
  {
    "labels": {
      "alertname": "TestAlert",
      "severity": "critical",
      "instance": "localhost:9090"
    },
    "annotations": {
      "summary": "Test alert from curl",
      "description": "This is a test alert"
    }
  }
]'

# Voir les alertes actives
curl http://localhost:9093/api/v1/alerts

# CrÃ©er un silence (mute pendant maintenance)
curl -X POST http://localhost:9093/api/v1/silences -d '{
  "matchers": [
    {
      "name": "instance",
      "value": "localhost:9090",
      "isRegex": false
    }
  ],
  "startsAt": "2024-01-20T10:00:00Z",
  "endsAt": "2024-01-20T12:00:00Z",
  "createdBy": "admin",
  "comment": "Maintenance planifiÃ©e"
}'
```

---

## Blackbox Exporter : Sondes SynthÃ©tiques

### Le Besoin

**ProblÃ¨me :** Votre serveur Nginx tourne (CPU/RAM OK), mais votre site est-il accessible ?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           MONITORING TRADITIONNEL (Insuffisant)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Node Exporter :                                            â”‚
â”‚  âœ… CPU: 20%                                                â”‚
â”‚  âœ… RAM: 40%                                                â”‚
â”‚  âœ… Disk: 60%                                               â”‚
â”‚                                                              â”‚
â”‚  Mais...                                                    â”‚
â”‚  âŒ Le site web retourne-t-il 200 OK ?                     â”‚
â”‚  âŒ Le certificat SSL est-il valide ?                       â”‚
â”‚  âŒ Le DNS rÃ©sout-il correctement ?                         â”‚
â”‚  âŒ La latence est-elle acceptable ?                        â”‚
â”‚                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           BLACKBOX EXPORTER (Monitoring SynthÃ©tique)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Simule un client rÃ©el :                                    â”‚
â”‚  âœ… HTTP GET https://myapp.com â†’ 200 OK                     â”‚
â”‚  âœ… TLS cert expiry â†’ Valide 89 jours                       â”‚
â”‚  âœ… DNS lookup myapp.com â†’ 1.2.3.4                          â”‚
â”‚  âœ… ICMP ping 1.2.3.4 â†’ 12ms                                â”‚
â”‚                                                              â”‚
â”‚  Alerte si :                                                â”‚
â”‚  - Code HTTP != 200                                         â”‚
â”‚  - Latence > 2s                                             â”‚
â”‚  - Cert expire < 30j                                        â”‚
â”‚  - DNS timeout                                              â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Architecture Blackbox Exporter

```mermaid
flowchart LR
    A[Prometheus] -->|1. Scrape| B[Blackbox Exporter<br/>:9115]

    B -->|2. Probe HTTP| C[https://myapp.com]
    B -->|2. Probe DNS| D[DNS Server]
    B -->|2. Probe ICMP| E[1.2.3.4]

    C -->|3. Response<br/>200 OK| B
    D -->|3. Response<br/>1.2.3.4| B
    E -->|3. Pong| B

    B -->|4. Metrics| A

    A -->|5. Alert if<br/>probe_success=0| F[AlertManager]
```

**Flux d'exÃ©cution :**

1. Prometheus appelle Blackbox Exporter avec une target en paramÃ¨tre
2. Blackbox fait la requÃªte (HTTP/DNS/ICMP) vers la target
3. Blackbox retourne les mÃ©triques (success, duration, status_code)
4. Prometheus stocke et Ã©value les rÃ¨gles d'alerte
5. AlertManager notifie si problÃ¨me

---

### Configuration Blackbox Exporter

**Fichier `blackbox.yml` :**

```yaml
modules:
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # MODULE 1 : HTTP 2xx (VÃ©rifier code retour 200)
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  http_2xx:
    prober: http
    timeout: 5s
    http:
      valid_http_versions: ["HTTP/1.1", "HTTP/2.0"]
      valid_status_codes: [200]  # Accepter seulement 200
      method: GET
      follow_redirects: true
      preferred_ip_protocol: "ip4"

      # VÃ©rifier la prÃ©sence d'un texte dans la rÃ©ponse
      fail_if_body_not_matches_regexp:
        - "Welcome"

      # VÃ©rifier le certificat TLS
      tls_config:
        insecure_skip_verify: false

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # MODULE 2 : HTTP POST (API health check)
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  http_post_2xx:
    prober: http
    http:
      method: POST
      headers:
        Content-Type: application/json
      body: '{"status":"check"}'

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # MODULE 3 : ICMP Ping
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  icmp:
    prober: icmp
    timeout: 5s
    icmp:
      preferred_ip_protocol: "ip4"

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # MODULE 4 : DNS Lookup
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  dns:
    prober: dns
    timeout: 5s
    dns:
      query_name: "myapp.com"
      query_type: "A"
      valid_rcodes:
        - NOERROR
      validate_answer_rrs:
        fail_if_not_matches_regexp:
          - "1\\.2\\.3\\.4"  # VÃ©rifier que le DNS rÃ©sout bien vers cette IP

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # MODULE 5 : TCP Port Check
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  tcp_connect:
    prober: tcp
    timeout: 5s
    tcp:
      preferred_ip_protocol: "ip4"
```

---

### Configuration Prometheus (Le Trick du Relabeling)

**ProblÃ¨me :** Blackbox Exporter ne scrape pas directement les targets. Il faut passer la target en paramÃ¨tre d'URL.

**Solution :** Relabeling dans Prometheus.

```yaml
# ============================================================
# PROMETHEUS : Job Blackbox Exporter
# ============================================================

scrape_configs:
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # JOB 1 : HTTP Probes
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - job_name: 'blackbox-http'
    metrics_path: /probe
    params:
      module: [http_2xx]  # Utiliser le module http_2xx

    static_configs:
      - targets:
          - https://myapp.com
          - https://api.company.com/health
          - https://admin.company.com

    relabel_configs:
      # Ã‰tape 1 : Sauvegarder la target originale dans __param_target
      - source_labels: [__address__]
        target_label: __param_target

      # Ã‰tape 2 : Remplacer __address__ par l'adresse du Blackbox Exporter
      - source_labels: [__param_target]
        target_label: instance

      - target_label: __address__
        replacement: blackbox-exporter:9115  # Adresse du Blackbox Exporter

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # JOB 2 : ICMP Probes (Ping)
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - job_name: 'blackbox-icmp'
    metrics_path: /probe
    params:
      module: [icmp]

    static_configs:
      - targets:
          - 8.8.8.8        # Google DNS
          - 1.1.1.1        # Cloudflare DNS
          - 192.168.1.1    # Gateway interne

    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: blackbox-exporter:9115

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # JOB 3 : DNS Probes
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - job_name: 'blackbox-dns'
    metrics_path: /probe
    params:
      module: [dns]

    static_configs:
      - targets:
          - 8.8.8.8        # RÃ©soudre via Google DNS
          - 1.1.1.1        # RÃ©soudre via Cloudflare DNS

    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: blackbox-exporter:9115
```

!!! warning "Le Relabeling est INDISPENSABLE"
    Sans le relabeling, Prometheus essaiera de scraper directement `https://myapp.com/metrics`, ce qui Ã©chouera.

    Le relabeling transforme :
    ```
    https://myapp.com
    ```
    En :
    ```
    http://blackbox-exporter:9115/probe?target=https://myapp.com&module=http_2xx
    ```

---

### MÃ©triques Blackbox Essentielles

```promql
# Probe rÃ©ussie (1) ou Ã©chouÃ©e (0)
probe_success{job="blackbox-http"}

# DurÃ©e de la requÃªte HTTP
probe_http_duration_seconds{job="blackbox-http"}

# Code de statut HTTP
probe_http_status_code{job="blackbox-http"}

# Expiration du certificat SSL (en secondes)
probe_ssl_earliest_cert_expiry{job="blackbox-http"}

# DurÃ©e du ping ICMP
probe_icmp_duration_seconds{job="blackbox-icmp"}

# RÃ©solution DNS rÃ©ussie
probe_dns_lookup_time_seconds{job="blackbox-dns"}
```

---

### RÃ¨gles d'Alerte Blackbox

```yaml
# prometheus-rules.yml

groups:
  - name: blackbox-alerts
    interval: 30s
    rules:
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # ALERTE 1 : Site web down
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - alert: WebsiteDown
        expr: probe_success{job="blackbox-http"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Site web {{ $labels.instance }} est DOWN"
          description: "Le site {{ $labels.instance }} ne rÃ©pond pas depuis 2 minutes."

      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # ALERTE 2 : Latence HTTP Ã©levÃ©e
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - alert: HighHTTPLatency
        expr: probe_http_duration_seconds{job="blackbox-http"} > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Latence HTTP Ã©levÃ©e sur {{ $labels.instance }}"
          description: "La latence est de {{ $value }}s (seuil: 2s)"

      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # ALERTE 3 : Certificat SSL expire bientÃ´t
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - alert: SSLCertExpiringSoon
        expr: (probe_ssl_earliest_cert_expiry - time()) / 86400 < 30
        for: 1h
        labels:
          severity: warning
        annotations:
          summary: "Certificat SSL expire dans {{ $value }} jours"
          description: "Le certificat de {{ $labels.instance }} expire bientÃ´t."

      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # ALERTE 4 : Ping Ã©levÃ© (rÃ©seau lent)
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - alert: HighPingLatency
        expr: probe_icmp_duration_seconds{job="blackbox-icmp"} > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Ping Ã©levÃ© vers {{ $labels.instance }}"
          description: "Latence ICMP: {{ $value }}s (seuil: 100ms)"
```

---

## La Stack ELK : Elasticsearch, Logstash, Kibana

### ELK vs Loki : Quand Utiliser Quoi ?

| Aspect | ELK (Elasticsearch, Logstash, Kibana) | Loki (Grafana Loki) |
|--------|---------------------------------------|---------------------|
| **Indexation** | Full-text search (tous les champs) | Labels uniquement (comme Prometheus) |
| **Stockage** | Lourd (indexe tout) | LÃ©ger (indexe les labels) |
| **RequÃªtes** | Complexes (regex, agrÃ©gations) | Simples (grep distribuÃ©) |
| **Performance** | Excellent pour recherche complexe | Excellent pour logs corrÃ©lÃ©s aux mÃ©triques |
| **CoÃ»t** | Ã‰levÃ© (CPU, RAM, Disk) | Faible |
| **Cas d'usage** | Analyse forensic, Compliance, SIEM | Debugging DevOps, CorrÃ©lation mÃ©triques |
| **IntÃ©gration** | Kibana (UI dÃ©diÃ©e) | Grafana (UI unifiÃ©e mÃ©triques + logs) |

**Recommandation :**

- **ELK** : Logs applicatifs lourds, recherche full-text, compliance (audit trail)
- **Loki** : Logs systÃ¨me/container, debugging DevOps, corrÃ©lation avec Prometheus

!!! tip "Pourquoi pas les deux ?"
    Beaucoup d'organisations utilisent **Loki** pour les logs quotidiens (debugging, monitoring) et **ELK** pour l'archivage long-terme et l'analyse forensic.

---

### Architecture ELK

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PIPELINE ELK                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Application                                                â”‚
â”‚  â”œâ”€â”€ app.log                                                â”‚
â”‚  â”‚                                                           â”‚
â”‚  â–¼                                                           â”‚
â”‚  Filebeat (Agent lÃ©ger)                                     â”‚
â”‚  â”œâ”€â”€ Lit les logs                                           â”‚
â”‚  â”œâ”€â”€ Envoie vers Logstash ou directement ES                 â”‚
â”‚  â”‚                                                           â”‚
â”‚  â–¼                                                           â”‚
â”‚  Logstash (ETL)                                             â”‚
â”‚  â”œâ”€â”€ Parse (Grok)                                           â”‚
â”‚  â”œâ”€â”€ Enrich (GeoIP, User-Agent)                             â”‚
â”‚  â”œâ”€â”€ Filter                                                 â”‚
â”‚  â”‚                                                           â”‚
â”‚  â–¼                                                           â”‚
â”‚  Elasticsearch (Stockage)                                   â”‚
â”‚  â”œâ”€â”€ Indexe les logs                                        â”‚
â”‚  â”œâ”€â”€ Recherche full-text                                    â”‚
â”‚  â”‚                                                           â”‚
â”‚  â–¼                                                           â”‚
â”‚  Kibana (Visualisation)                                     â”‚
â”‚  â””â”€â”€ Dashboards, Recherche, Alertes                         â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Stack ELK avec Docker Compose

**Fichier `docker-compose.yml` (Stack minimale) :**

```yaml
version: '3.8'

services:
  # ============================================================
  # ELASTICSEARCH (Stockage)
  # ============================================================
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.3
    container_name: elasticsearch
    environment:
      - discovery.type=single-node         # Mode single-node (dev/test)
      - xpack.security.enabled=false       # DÃ©sactiver la sÃ©curitÃ© (dev uniquement)
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"   # Heap size
    ports:
      - "9200:9200"
    volumes:
      - es_data:/usr/share/elasticsearch/data
    networks:
      - elk

  # ============================================================
  # KIBANA (Interface Web)
  # ============================================================
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.3
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    networks:
      - elk

  # ============================================================
  # LOGSTASH (ETL)
  # ============================================================
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.3
    container_name: logstash
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml
    ports:
      - "5044:5044"  # Beats input
      - "9600:9600"  # Logstash API
    environment:
      - "LS_JAVA_OPTS=-Xms256m -Xmx256m"
    depends_on:
      - elasticsearch
    networks:
      - elk

  # ============================================================
  # FILEBEAT (Agent)
  # ============================================================
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.3
    container_name: filebeat
    user: root
    volumes:
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    command: filebeat -e -strict.perms=false
    depends_on:
      - logstash
    networks:
      - elk

volumes:
  es_data:
    driver: local

networks:
  elk:
    driver: bridge
```

---

### Configuration Logstash (Pipeline)

**Fichier `logstash/pipeline/logstash.conf` :**

```ruby
# ============================================================
# LOGSTASH PIPELINE
# ============================================================

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# INPUT : Recevoir depuis Filebeat
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
input {
  beats {
    port => 5044
  }
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# FILTER : Parser et enrichir
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
filter {
  # Parser les logs JSON
  if [message] =~ /^\{/ {
    json {
      source => "message"
    }
  }

  # Parser les logs Nginx (format combined)
  if [fields][log_type] == "nginx" {
    grok {
      match => { "message" => '%{IPORHOST:clientip} - %{USER:ident} \[%{HTTPDATE:timestamp}\] "%{WORD:method} %{DATA:request} HTTP/%{NUMBER:httpversion}" %{NUMBER:response:int} (?:-|%{NUMBER:bytes:int}) %{QS:referrer} %{QS:agent}' }
    }

    # Convertir la date
    date {
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
      target => "@timestamp"
    }

    # GeoIP sur l'IP client
    geoip {
      source => "clientip"
      target => "geoip"
    }

    # Parser le User-Agent
    useragent {
      source => "agent"
      target => "user_agent"
    }
  }

  # Parser les logs applicatifs (format standard)
  if [fields][log_type] == "application" {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} \[%{DATA:thread}\] %{DATA:logger} - %{GREEDYDATA:log_message}" }
    }
  }

  # Ajouter des tags
  mutate {
    add_field => { "environment" => "production" }
    remove_field => [ "message" ]  # Supprimer le message brut si parsÃ©
  }
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# OUTPUT : Envoyer vers Elasticsearch
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "logs-%{[fields][log_type]}-%{+YYYY.MM.dd}"
  }

  # Debug : Afficher dans stdout
  stdout {
    codec => rubydebug
  }
}
```

---

### Configuration Filebeat

**Fichier `filebeat/filebeat.yml` :**

```yaml
filebeat.inputs:
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # INPUT 1 : Logs Docker containers
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - type: container
    paths:
      - '/var/lib/docker/containers/*/*.log'
    fields:
      log_type: docker
    fields_under_root: true

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # INPUT 2 : Logs Nginx
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - type: log
    enabled: true
    paths:
      - /var/log/nginx/access.log
    fields:
      log_type: nginx
    fields_under_root: true

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # INPUT 3 : Logs application
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - type: log
    enabled: true
    paths:
      - /var/log/myapp/*.log
    fields:
      log_type: application
    fields_under_root: true
    multiline.pattern: '^[0-9]{4}-[0-9]{2}-[0-9]{2}'
    multiline.negate: true
    multiline.match: after

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# OUTPUT : Envoyer vers Logstash
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
output.logstash:
  hosts: ["logstash:5044"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LOGGING
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644
```

---

### Lancer la Stack ELK

```bash
# DÃ©marrer la stack
docker-compose up -d

# Attendre qu'Elasticsearch soit prÃªt (30s-1min)
curl -X GET "localhost:9200/_cluster/health?wait_for_status=yellow&timeout=50s&pretty"

# AccÃ©der Ã  Kibana
# http://localhost:5601

# VÃ©rifier les indices crÃ©Ã©s
curl -X GET "localhost:9200/_cat/indices?v"

# Rechercher des logs
curl -X GET "localhost:9200/logs-*/_search?pretty"
```

---

## SRE Golden Signals : Les 4 MÃ©triques qui Comptent

### ThÃ©orie Google SRE

**Les 4 signaux dorÃ©s = Les 4 mÃ©triques essentielles pour monitorer n'importe quel systÃ¨me.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   GOLDEN SIGNALS (Google)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  1. LATENCY (Latence)                                       â”‚
â”‚     Temps de rÃ©ponse d'une requÃªte                          â”‚
â”‚     Outil : Blackbox Exporter, Application metrics          â”‚
â”‚     Alerte : P95 > 2s                                       â”‚
â”‚                                                              â”‚
â”‚  2. TRAFFIC (Trafic)                                        â”‚
â”‚     Charge sur le systÃ¨me (req/s, connexions/s)             â”‚
â”‚     Outil : Nginx metrics, HAProxy metrics                  â”‚
â”‚     Alerte : Augmentation soudaine > 200%                   â”‚
â”‚                                                              â”‚
â”‚  3. ERRORS (Erreurs)                                        â”‚
â”‚     Taux d'erreur (5xx, failed requests)                    â”‚
â”‚     Outil : Blackbox Exporter, Logs (ELK)                   â”‚
â”‚     Alerte : Error rate > 5%                                â”‚
â”‚                                                              â”‚
â”‚  4. SATURATION (Saturation)                                 â”‚
â”‚     Utilisation des ressources (CPU, RAM, Disk, Network)    â”‚
â”‚     Outil : Node Exporter                                   â”‚
â”‚     Alerte : CPU > 80%, RAM > 90%, Disk > 85%               â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Mapping avec nos Outils

| Golden Signal | MÃ©trique Prometheus | Outil |
|---------------|---------------------|-------|
| **Latency** | `probe_http_duration_seconds` | Blackbox Exporter |
| | `http_request_duration_seconds` | Application (Instrumentation) |
| **Traffic** | `nginx_http_requests_total` | Nginx Exporter |
| | `haproxy_frontend_connections_total` | HAProxy Exporter |
| **Errors** | `probe_success == 0` | Blackbox Exporter |
| | `http_requests_total{code=~"5.."}` | Application (Instrumentation) |
| **Saturation** | `node_cpu_seconds_total` | Node Exporter |
| | `node_memory_MemAvailable_bytes` | Node Exporter |
| | `node_filesystem_avail_bytes` | Node Exporter |

---

### Exemple de Dashboard SRE

**RequÃªtes PromQL pour un Dashboard Golden Signals :**

```promql
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. LATENCY (P95 des 5 derniÃ¨res minutes)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
histogram_quantile(0.95,
  rate(http_request_duration_seconds_bucket[5m])
)

# Ou pour Blackbox
probe_http_duration_seconds{job="blackbox-http"}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. TRAFFIC (RequÃªtes par seconde)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
rate(nginx_http_requests_total[1m])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. ERRORS (Taux d'erreur 5xx)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
sum(rate(http_requests_total{code=~"5.."}[5m]))
/
sum(rate(http_requests_total[5m])) * 100

# Ou pour Blackbox
avg_over_time(probe_success{job="blackbox-http"}[5m]) * 100

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. SATURATION (Utilisation CPU)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
100 - (avg(irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

# Saturation RAM
100 - ((node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100)

# Saturation Disk
100 - ((node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100)
```

---

## Quick Reference

### Ports par DÃ©faut

| Service | Port | Description |
|---------|------|-------------|
| **AlertManager** | 9093 | API et UI AlertManager |
| **Blackbox Exporter** | 9115 | Metrics endpoint |
| **Elasticsearch** | 9200 | API HTTP |
| **Elasticsearch** | 9300 | Communication inter-nÅ“uds |
| **Kibana** | 5601 | Interface Web |
| **Logstash** | 5044 | Beats input |
| **Logstash** | 9600 | Monitoring API |

---

### Commandes de Test

```bash
# ============================================================
# ALERTMANAGER
# ============================================================

# VÃ©rifier l'Ã©tat
curl http://localhost:9093/-/healthy

# Lister les alertes actives
curl http://localhost:9093/api/v1/alerts

# CrÃ©er une alerte de test
curl -X POST http://localhost:9093/api/v1/alerts -d '[
  {
    "labels": {"alertname": "TestAlert", "severity": "critical"},
    "annotations": {"summary": "Test"}
  }
]'

# ============================================================
# BLACKBOX EXPORTER
# ============================================================

# VÃ©rifier l'Ã©tat
curl http://localhost:9115/metrics

# Tester un probe HTTP
curl "http://localhost:9115/probe?target=https://google.com&module=http_2xx"

# Tester un probe ICMP
curl "http://localhost:9115/probe?target=8.8.8.8&module=icmp"

# ============================================================
# ELASTICSEARCH
# ============================================================

# VÃ©rifier l'Ã©tat du cluster
curl http://localhost:9200/_cluster/health?pretty

# Lister les indices
curl http://localhost:9200/_cat/indices?v

# Rechercher des logs
curl -X GET "http://localhost:9200/logs-*/_search?pretty" -H 'Content-Type: application/json' -d'
{
  "query": {
    "match": {
      "level": "ERROR"
    }
  }
}'

# ============================================================
# KIBANA
# ============================================================

# VÃ©rifier l'Ã©tat
curl http://localhost:5601/api/status

# AccÃ©der Ã  l'UI
# http://localhost:5601
```

---

### RÃ©fÃ©rence Rapide ComplÃ¨te

```yaml
# ============================================================
# ALERTMANAGER : Routage
# ============================================================

route:
  receiver: 'default'
  group_by: ['alertname', 'cluster']
  routes:
    - match:
        severity: critical
      receiver: 'pagerduty'

receivers:
  - name: 'slack'
    slack_configs:
      - channel: '#alerts'

# ============================================================
# BLACKBOX : Probe HTTP
# ============================================================

# prometheus.yml
- job_name: 'blackbox-http'
  metrics_path: /probe
  params:
    module: [http_2xx]
  static_configs:
    - targets: ['https://myapp.com']
  relabel_configs:
    - source_labels: [__address__]
      target_label: __param_target
    - target_label: __address__
      replacement: blackbox:9115

# ============================================================
# ELK : Docker Compose
# ============================================================

version: '3.8'
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.3
    environment:
      - discovery.type=single-node
    ports:
      - "9200:9200"

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.3
    ports:
      - "5601:5601"
```
